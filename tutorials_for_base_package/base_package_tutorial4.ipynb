{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorials about SecureEvaluator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc451e17cac7454"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:02:36.355699Z",
     "start_time": "2024-07-01T09:02:31.963628Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from llm4ad.base import Evaluation, SecureEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The user should implement 'alevo.base.Evaluator' class and override the 'evaluate_program' function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e1f0f2b98d2e430"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MyEvaluator(Evaluation):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            use_numba_accelerate=True,  # try to set to 'False' and execute \n",
    "            use_protected_div=True,  # \n",
    "            timeout_seconds=5, \n",
    "        )\n",
    "    \n",
    "    # the user should override this function.\n",
    "    def evaluate_program(self, program_str: str, callable_func: callable) -> Any | None:\n",
    "        # we consider a \"dummy evaluation\" for the function:\n",
    "        # we call (invoke) the function and get its return value as the score of this function\n",
    "        score = callable_func()\n",
    "        return score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:02:38.122529Z",
     "start_time": "2024-07-01T09:02:38.117676Z"
    }
   },
   "id": "31ba8b132549f719"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "evaluator = SecureEvaluator(evaluator=MyEvaluator(), debug_mode=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:04:04.292198Z",
     "start_time": "2024-07-01T09:04:04.279473Z"
    }
   },
   "id": "9ebf2203f9a90e0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "program = \"\"\"\n",
    "import random\n",
    "\n",
    "def f():\n",
    "    return random.random() / random.random()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:04:05.098915Z",
     "start_time": "2024-07-01T09:04:05.091739Z"
    }
   },
   "id": "7056a51766f59da8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: evaluated program:\n",
      "import numba\n",
      "import random\n",
      "\n",
      "@numba.jit(nopython=True)\n",
      "def f():\n",
      "    return random.random()\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4931259936824106"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluator.evaluate_program(program)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:04:06.573028Z",
     "start_time": "2024-07-01T09:04:05.622917Z"
    }
   },
   "id": "8fd8e5bf136a3201"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "program = \"\"\"\n",
    "import random\n",
    "\n",
    "def f():\n",
    "    while True:\n",
    "        pass\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:04:16.612757Z",
     "start_time": "2024-07-01T09:04:16.604959Z"
    }
   },
   "id": "318acb26920a4b6a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: evaluated program:\n",
      "import numba\n",
      "import random\n",
      "\n",
      "@numba.jit(nopython=True)\n",
      "def f():\n",
      "    while True:\n",
      "        pass\n",
      "DEBUG: the evaluation time exceeds 5s.\n"
     ]
    }
   ],
   "source": [
    "score = evaluator.evaluate_program(program)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T09:04:41.182801Z",
     "start_time": "2024-07-01T09:04:36.133393Z"
    }
   },
   "id": "7f16d7f44e183f6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "53f8808398d57b86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
